{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final para el Laboratorio de Machine Learning - ITBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo: clasificación de artículos periodísticos en categorías\n",
    "\n",
    "El objetivo de este proyecto es desarrollar una aplicación capaz de tomar un texto periodístico y, en base a su contenido, determinar a qué categoría pertenece. Las categorías elegidas son las siguientes:\n",
    "\n",
    "* Política\n",
    "* Economía\n",
    "* Deportes\n",
    "* Entretenimiento\n",
    "* Tecnología\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Reuters Corpora (RCV1)\n",
    "\n",
    "http://trec.nist.gov/data/reuters/reuters.html\n",
    "\n",
    "El dataset consiste de alrededor de 800.000 artículos periodísticos en formato XML, que van desde 1996-08-20 a 1997-08-19 (un año completo). De cada XML nos interesan los campos: título, cuerpo de la noticia y categorías.\n",
    "\n",
    "### Preprocesamiento\n",
    "\n",
    "El preprocesamiento de los archivos de Reuters se realizó con el siguiente script:\n",
    "\n",
    "[Reuters - preprocessing.ipynb](./Reuters - preprocessing.ipynb)\n",
    "\n",
    "Del total de artículos se procesan sólo los que pertenecen a las categorías elegidas, con lo cual nos quedamos con un total de aproximadamente 202.400 archivos.\n",
    "\n",
    "La distribución de cantidad de artículos por categoría queda un poco desbalanceada:\n",
    "```\n",
    " ECONOMICS:     117.539\n",
    " ENTERTAINMENT:   3.801\n",
    " POLITICS:       56.878\n",
    " SPORTS:         35.317\n",
    " TECHNOLOGY:      2.410\n",
    "```\n",
    "\n",
    "**Nota:** Un artículo puede pertenecer a más de una catagoría, de hecho 13.500 artículos son multi-categoría:\n",
    "```\n",
    " POLITICS_ECONOMICS:        12.948\n",
    " ENTERTAINMENT_POLITICS:       272\n",
    " ENTERTAINMENT_ECONOMICS:       48\n",
    " ENTERTAINMENT_TECHNOLOGY:      40\n",
    " POLITICS_TECHNOLOGY:           46\n",
    " POLITICS_TECHNOLOGY_ECONOMICS:  6\n",
    " SPORTS_ECONOMICS:              39\n",
    " SPORTS_ENTERTAINMENT:          15\n",
    " SPORTS_POLITICS:               26\n",
    " SPORTS_POLITICS_ECONOMICS:      7\n",
    " SPORTS_TECHNOLOGY:              1\n",
    " SPORTS_ENTERTAINMENT_POLITICS:  1\n",
    " TECHNOLOGY_ECONOMICS:          33\n",
    " ENTERTAINMENT_TECHNOLOGY_POLITICS: 2\n",
    " POLITICS_ENTERTAINMENT_ECONOMICS: 23\n",
    "```\n",
    "\n",
    "Ejemplo de XML original: [../rcv1/19960820/4155newsML.xml](./4155newsML.xml)\n",
    "\n",
    "Ejemplo de TXT convertido (../converted/19960820/4155-POLITICS_ECONOMICS): \n",
    "\n",
    "<pre>\n",
    "California asks U.S. to repay its Civil War debt.\n",
    "California's state Senate passed a resolution Monday urging President Clinton and the Congress to reimburse the state for expenses it incurred during the Civil War.Republican Assemblyman Mickey Conroy's resolution moved with little fanfare through the state Legislature. It was approved late Monday by the Senate by a vote of 32-to-1. It was backed earlier this year in the state Assembly.The resolution \"memorializes\" Clinton and Congress to enact legislation that would finally repay the long-forgotten Civil War debt, now estimated to be worth $82 million.Conroy maintains the Civil War debt represents the first unfunded mandate imposed on California by Washington.In the early 1860s, the Congress and the administration of President Abraham Lincoln solicited financial support from the...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T17:25:16.088652Z",
     "start_time": "2017-12-18T17:25:16.085198Z"
    }
   },
   "source": [
    "## Clasificación con CountVectorizer + FNN\n",
    "\n",
    "La primera idea es ver qué sucede con una simple FNN cuya entrada sea la matriz generada con CountVectorizer.\n",
    "\n",
    "### CountVectorizing\n",
    "\n",
    "El siguiente script es el encargado de procesar los artículos y generar la matriz que tendrá una fila por artículo y  columnas que corresponden a la cantidad de palabras encontradas por cada artículo:\n",
    "\n",
    "[CountVectorizer.ipynb](./CountVectorizer.ipynb)\n",
    "\n",
    "El countvectorizer utiliza la función `tokenize_and_stem` para tokenizar y reducir la cantidad de token mediante stemming.\n",
    "\n",
    "El resultado es una matriz sparse de (202399, 84168) que se almacena en `countvect-articles.mtx` para luego ser utilizado en la etaba de entrenamiento de la FNN.\n",
    "\n",
    "### FNN\n",
    "\n",
    "La red neuronal más sencilla es simplemente una capa densa con 5 salidas, una por cada una de las categorías que nos interesan. La cantidad de entradas corresponde a las 84K columnas de la cantidad de palabras por artículo, con lo cual queda una red con (84168 * 5) + 5 = 420.845 parámetros. El script de entrenamiento es el siguiente:\n",
    "\n",
    "[FNN-from-countvectorizer.ipynb](./FNN-from-countvectorizer.ipynb)\n",
    "\n",
    "El resultado del entrenamiento da a priori un buen resultado con el set de validación, **0.9766**.\n",
    "\n",
    "Luego del entrenamiento se hicieron pruebas puntuales con textos actuales copiados de sitios de internet con buenos resultados.\n",
    "\n",
    "También se calculó la precisión con el dataset de test, pero aceptando sólo los resultados de clasificación exactos, es decir, que las 5 categorías dieran el valor de los labels, y dio una precisión de **0.9053**. Siendo más flexibles y aceptando que predijo alguna de las categorías, la presición sube a **0.9473**.\n",
    "\n",
    "También se realizó un experimento con otra fórmula de loss llamada [kullback_leibler_divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence), pero los resultados no fueron mejores:\n",
    "\n",
    "[FNN-KL.ipynb](./FNN-KL.ipynb)\n",
    "\n",
    "**Pendiente**: Hacer pruebas cambiando los valores de *count* por valores normalizados o simplemente un \"1\" si existe la palabra en la noticia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-19T15:09:19.190312Z",
     "start_time": "2017-12-19T15:09:19.187877Z"
    }
   },
   "source": [
    "## Clasificación con Word2Vec + CNN\n",
    "\n",
    "Existen varios estudios de NLP en los cuales se aplican redes convolucionales para reducir la cantidad de parámetros necesarios para entrenar la red, uno de los papers es el siguiente:\n",
    "\n",
    "[Convolutional Neural Networks for Sentence Classification by Yoon Kim](https://arxiv.org/pdf/1408.5882v2.pdf)\n",
    "\n",
    "La idea consiste en separar el entrenamiento en dos partes: 1) entrenar una matriz de word embedding utilizando  gensim-Word2vec para generar una matriz con el vocabulario propio del dataset de Reuters, y 2) entrenar una red convolucional dejando los pesos fijos de la capa de embedding.\n",
    "\n",
    "El siguiente esquema explica cómo se arma la red:\n",
    "\n",
    "<img src=\"http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM-1024x937.png\"/>\n",
    "\n",
    "A continuación se explican cada una de las etapas:\n",
    "\n",
    "### Word2vec\n",
    "\n",
    "El siguiente script es el encargado de procesar los artículos mediante gensim-word2vec:\n",
    "\n",
    "[Word2Vec training.ipynb](./Word2Vec training.ipynb)\n",
    "\n",
    "El entrenamiento con word2vec es sencillo, simplemente hubo que crear un generador capaz de iterar sobre todos los archivos. Se seleccionó un tamaño de vector de 300 de manera que sea compatible con vectores generados por terceros, lo que nos permitirá luego comparar las soluciones aplicando *transfer learning*.\n",
    "\n",
    "El resultado del entrenamiento es una matriz de 84.000 términos x 300 (tamaño del vector), y que corresponde al primer rectángulo blanco de la imagen anterior. Los pesos de dicha matriz quedan fijos, es decir, no son pesos \"entrenables\" en la etapa siguiente.\n",
    "\n",
    "### CNN\n",
    "\n",
    "La red completa se arma ahora con una primera capa convolucional **1D** formada por filtros de distintos tamaños (3, 4, 5 y 6 palabras de largo) y se agregan 2 de cada tamaño. En la figura corresponden a los primeros rectángulos de colores.\n",
    "\n",
    "Luego siguen las etapas de MaxPooling1D que reducen los tamaños de la salida de los filtros en 10x. Las salidas luego se hacen \"flatten\" para pasar a una única dimensión y finalmente se concatenan todas, quedando así listo para entrar a la última capa densa de clasificación.\n",
    "\n",
    "[CNN-from-word2vec.ipynb](./CNN-from-word2vec.ipynb)\n",
    "\n",
    "El entrenamiento da como resultado del set de validación **0.9804** y la clasificación de prueba con textos actuales es satisfactoria.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning utilizando pre-trained Word2vec de Google\n",
    "\n",
    "Google puso a disposición word embeddings pre entrenados con distintos datos, y en particular el que nos interesa a nosotros es el que surge de un dataset de Google News, que da como resultado una matriz de 1 millón de palabras (case sensitive, con bigrams y trigrams) y con el mismo tamaño de vector de 300. Ver:\n",
    "\n",
    "[https://code.google.com/archive/p/word2vec/](https://code.google.com/archive/p/word2vec/)\n",
    "\n",
    "[Google's trained Word2Vec model in Python](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/)\n",
    "\n",
    "Se tomó la misma CNN del punto anterior y simplemente se reemplazó el embedding propio por el de Google.\n",
    "\n",
    "Curiosamente los resultados obtenidos son similares a los anteriores.\n",
    "\n",
    "**Ventajas:** se ahorra el proceso de entrenamiento de word2vec.\n",
    "\n",
    "**Desventajas:** se necesita mucha memoria para alojar la matriz de word2vec y un diccionarios para convertir palabras en índices, necesarios para la etapa de entrenamiento de la CNN.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación con RNN y word2vec\n",
    "\n",
    "La idea es armar una simple RNN donde la variable \"tiempo\" en realidad son las secuencias vectores de las palabras que forman un artículo. La estructura es sencilla:\n",
    "\n",
    "``` python\n",
    "model = Sequential()\n",
    "model.add(w2v_model.wv.get_keras_embedding(train_embeddings=False))\n",
    "model.add(GRU(100))\n",
    "model.add(Dense(NUM_CATEGORIES, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "```\n",
    "<pre>\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "embedding_1 (Embedding)      (None, None, 300)         19272000  \n",
    "_________________________________________________________________\n",
    "gru_1 (GRU)                  (None, 100)               120300    \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 5)                 505       \n",
    "=================================================================\n",
    "Total params: 19,392,805\n",
    "Trainable params: 120,805\n",
    "Non-trainable params: 19,272,000\n",
    "</pre>\n",
    "\n",
    "El entrenamiento se hace lento debido a la característica secuencial de las RNN, pero los resultados parecen ser prometedores:\n",
    "\n",
    "[RNN-word2vec.ipynb](./RNN-word2vec.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros experimentos\n",
    "\n",
    "* [CNN-from-word2vec-trainable.ipynb](./CNN-from-word2vec-trainable.ipynb)\n",
    "\n",
    "\n",
    "* [W2V-GAP-FC.ipynb](./W2V-GAP-FC.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "* El problema de clasificación \"multi label\" (la noticia puede pertenecer a más de una categoría) trae algunos desafíos extra con respecto al \"multi class\", al menos en cuanto a la forma de medir la precisión. Existen algunas propuestas con modelos alternativos que no fueron experimentados: [Introdiction to multi label classification](https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/).\n",
    "\n",
    "\n",
    "* Tanto la FNN como la CNN dan buenos resultados, pero es posible mejorarlos estudiando mejor las palabras que forman el CountVectorizer y el Word2vec (agregando stopwords, por ejemplo).\n",
    "\n",
    "\n",
    "* Fue una buena práctica para mejorar el conocimiento de las FNN, CNN, Word2Vec, etc., además de las herramientas de base: Numpy, Keras, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
